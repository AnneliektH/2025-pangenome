{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33fc90a",
   "metadata": {},
   "source": [
    "### Redoing pangenome calculations using Roary and Sourmash.\n",
    "Sourmash pangenome plugin was changed a bit. \n",
    "Pipeline collects all microbial genomes of species. Then dereplicates them at 99% ANI, and runs prokka for protein predictions. The protein predictions are used by roary, to define core, soft core, shell and cloud genes for the microbial species. \n",
    "\n",
    "Roary returns a (not-so-handy) presence/absence file for all genes found in all strains. This needs to be input in a python script to get lists of gene names, that are in each category. Can use that to filter fasta files, to get a 'cloud' and 'core' fasta file in DNA space. This is then (again) put into prokka, to predict the genes, so that we also have a 'cloud' and 'core' fasta in AA space.\n",
    "\n",
    "For now, only uses reference strains. Will add using host (pig) specific strains later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5525b3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# update plugin\n",
    "mamba activate pangenomics_dev\n",
    "\n",
    "# upgrade\n",
    "pip install --upgrade --force-reinstall git+https://github.com/dib-lab/sourmash_plugin_pangenomics.git\n",
    "\n",
    "# install tables plugin\n",
    "mamba activate pangenomics_dev\n",
    "git clone https://github.com/sourmash-bio/sourmash_plugin_tables.git\n",
    "cd sourmash_plugin_tables\n",
    "pip install -e .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557aec22",
   "metadata": {},
   "source": [
    "#### Steps to get from a species name to a pangenome sketch (protein and nucleotide)\n",
    "I want to be able to go from species name, to a merged pangenome sketch, in both protein and nucleotide sketch. For now i am only interested in the core and cloud sketch, not in soft core or shell. \n",
    "\n",
    "I would like to add a separate workflow in which we can add species specific strains, such as all newly assembled pig stuff, but would first like for it to work on just reference genomes. \n",
    "\n",
    "**Steps**:\n",
    "1. get all genomes of species of interest, then dereplicate (1_collect_genomes.smk)\n",
    "2. Run prokka on the genomes, then run roary (2_roary.smk)\n",
    "3. Take roary output, and make separate fasta files for core and cloud genes (3_genes_to_hash.smk). \n",
    "\n",
    "**TODO**: Translate to protein and convert into hashes (3_genes_to_hash.smk), so that we have a sketch for all core and all cloud genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949373b2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# where is the tax file:\n",
    "/group/ctbrowngrp2/scratch/annie/2023-swine-sra/results/MAGs/250411_mag_taxonomy.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335045bd",
   "metadata": {},
   "source": [
    "### Steps to add: \n",
    "Not yet implemented:\n",
    "- nucl fasta to sig in dna space\n",
    "\n",
    "Either:\n",
    "- nucl fasta translated to protein\n",
    "OR\n",
    "- nucl fasta into prokka, then faa file to protein\n",
    "\n",
    "Need to compare outputs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ad410",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Do a test with just reference genomes. (Megasphaera elsdenii)\n",
    "mkdir test_pipeline\n",
    "\n",
    "# see Snakefile\n",
    "# how to go from 2 lists of species to a folder with all of them: For drep. \n",
    "srun --account=ctbrowngrp -p med2 -J roary -t 4:00:00 -c 24 --mem=80gb --pty bash\n",
    "mamba activate branchwater-skipmer\n",
    "\n",
    "snakemake --use-conda --resources mem_mb=80000 --rerun-triggers mtime \\\n",
    "-c 24 --rerun-incomplete -k -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827c684",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# gene presence absemce file\n",
    "# how to get to those lists, then files?\n",
    "python /group/ctbrowngrp2/amhorst/2025-pangenome/workflow/scripts/count_genes.py \\\n",
    "gene_presence_absence.Rtab test.csv\n",
    "\n",
    "# gives files hard_core.txt, soft_core.txt, cloud.txt, shell.txt\n",
    "# with group numbers. Now how to get the sequence?\n",
    "# from pan_genome_reference.fa --> proteins?\n",
    "# and easiest is probs converting these sequences to AA\n",
    "mamba activate seqkit\n",
    "\n",
    "# test grabbing seqs of interest\n",
    "seqkit grep -r -n -f /group/ctbrowngrp2/amhorst/2025-pangenome/results/test_pipeline/m_elsdenii/roary/hard_core.txt \\\n",
    "/group/ctbrowngrp2/amhorst/2025-pangenome/results/test_pipeline/m_elsdenii/roary/pan_genome_reference.fa \\\n",
    "-o /group/ctbrowngrp2/amhorst/2025-pangenome/results/test_pipeline/m_elsdenii/sourmash/m_elsdenii.core.fa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25ddae",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# try it out in protein space:\n",
    "# downloaf and sketch metagenomes in translate\n",
    "cp m_elsdenii/sourmash/m_elsdenii.cloud.fa ./protein_space/\n",
    "\n",
    "# translate to protein with prokka\n",
    "mamba activate prokka\n",
    "\n",
    "prokka --kingdom Bacteria --outdir cloud_genes \\\n",
    "--norrna --notrna --prefix cloud --force \\\n",
    "--locustag cloud m_elsdenii.cloud.fa \n",
    "\n",
    "prokka --kingdom Bacteria --outdir core_genes \\\n",
    "--norrna --notrna --prefix core --force \\\n",
    "--locustag core m_elsdenii.core.fa \n",
    "\n",
    "\n",
    "# we can prob do sketch translate, then dont have to go back to prokka\n",
    "# lets compare outputs\n",
    "sourmash sketch translate -p k=10,scaled=500 m_elsdenii.core.fa -o m_elsdenii.core.tr.k10.zip\n",
    "sourmash sketch translate -p k=10,scaled=500 m_elsdenii.cloud.fa -o m_elsdenii.cloud.tr.k10.zip\n",
    "\n",
    "# also do protein sketches and see if different when crossing with metaG\n",
    "sourmash sketch protein cloud_genes/cloud.faa -p k=10,scaled=500 -o cloud_genes/cloud.prot.zip\n",
    "sourmash sketch protein core_genes/core.faa -p k=10,scaled=500 -o core_genes/core.prot.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61f0c5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42545d8f",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "Adding non-reference genomes. (now total of 95, 28 pig specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3881a7a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# add a drep rule for only the reference genomes and one for all\n",
    "srun --account=ctbrowngrp -p med2 -J roary -t 2:00:00 -c 24 --mem=50gb --pty bash\n",
    "mamba activate branchwater-skipmer\n",
    "\n",
    "dRep dereplicate drep_allMAGs -p 24 \\\n",
    "--ignoreGenomeQuality -pa 0.9 -sa 0.99 -nc 0.30 -cm larger \\\n",
    "-g MAGs/*.fasta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d5a97",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a080f38",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# now for protein space:\n",
    "# translated to protein with prokka\n",
    "\n",
    "sourmash sketch translate -p k=10,scaled=500\n",
    "\n",
    "sourmash sketch protein -p k=10,scaled=500 genome.faa\n",
    "\n",
    "sourmash sketch dna m_elsdenii.cloud.fa -o m_elsdenii.cloud.k21.zip -p k=21,scaled=1000 \n",
    "\n",
    "# try pangenome merge and ranktable (m2n3, k21, s50)\n",
    "sourmash scripts pangenome_merge m_elsdenii.cloud.k21.zip -k 21  \\\n",
    "-o m_elsdenii.cloud.pang.k21.zip --scaled 1000 \n",
    "\n",
    "sourmash scripts pangenome_ranktable \\\n",
    "m_elsdenii.cloud.pang.k21.zip -o m_elsdenii.cloud.k21.rank.csv \\\n",
    "-k 21 --scaled 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fea2a8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python ../../../workflow/scripts/calc-hash-presence.py \\\n",
    "m_elsdenii.core.k21.rank.csv pig_sra.txt --scaled=1000 -k 21 -o pig.x.core.dna.dmp\n",
    "\n",
    "\n",
    "python ../../../workflow/scripts/calc-hash-presence.py \\\n",
    "m_elsdenii.core.k21.rank.csv human_sra.txt --scaled=1000 -k 21 -o human.x.core.dna.dmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c4fc9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "        python ../../../workflow/scripts/parse-dump.py \\\n",
    "        --dump-files-1 pig.x.core.dna.dmp \\\n",
    "        --dump-files-2 human.x.core.dna.dmp > cmp_core.dna.csv"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
